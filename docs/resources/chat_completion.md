---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "openai_chat_completion Resource - terraform-provider-openai"
subcategory: ""
description: |-
  
---

# openai_chat_completion (Resource)



## Example Usage

```terraform
resource "openai_chat_completion" "example" {
  model = "gpt-4o-mini"

  messages {
    role    = "system"
    content = "You are a helpful assistant."
  }

  messages {
    role    = "user"
    content = "Hello! What's the weather like today?"
  }

  temperature = 0.7
  max_tokens  = 150
}

output "chat_response" {
  value = openai_chat_completion.example.choices[0].message[0].content
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `messages` (Block List, Min: 1) A list of messages comprising the conversation so far (see [below for nested schema](#nestedblock--messages))
- `model` (String) ID of the model to use for the chat completion

### Optional

- `_imported_resource` (String) Internal field to prevent recreation of imported resources
- `frequency_penalty` (Number) Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far
- `function_call` (String) Controls how the model responds to function calls. 'none' means the model doesn't call a function, 'auto' means the model can pick between calling a function or generating a message
- `functions` (Block List) A list of functions the model may generate JSON inputs for (see [below for nested schema](#nestedblock--functions))
- `imported` (Boolean) Whether this resource was imported from an existing chat completion
- `logit_bias` (Map of Number) Modify the likelihood of specified tokens appearing in the completion
- `max_tokens` (Number) The maximum number of tokens to generate in the chat completion
- `metadata` (Map of String) A map of key-value pairs that can be used to filter chat completions when listing them through the API. Only applicable when store is set to true.
- `n` (Number) How many chat completion choices to generate for each input message
- `presence_penalty` (Number) Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far
- `project_id` (String) The project to use for this request
- `stop` (List of String) Up to 4 sequences where the API will stop generating further tokens
- `store` (Boolean) Whether to store the chat completion for later retrieval via API. Note: requires a compatible model (e.g., gpt-4o), this parameter set to true, and the Chat Completions Store feature enabled on your OpenAI account. Without these conditions, completions won't be retrievable through the API.
- `stream` (Boolean) Whether to stream back partial progress
- `temperature` (Number) What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic
- `top_p` (Number) Nuclear sampling: consider the results of the tokens with top_p probability mass. Range from 0 to 1
- `user` (String) A unique identifier representing your end-user

### Read-Only

- `chat_completion_id` (String) The ID of the chat completion
- `choices` (Block List) The list of chat completion choices the model generated (see [below for nested schema](#nestedblock--choices))
- `created` (Number) The Unix timestamp (in seconds) of when the chat completion was created
- `id` (String) The ID of this resource.
- `model_used` (String) The model used for the chat completion
- `object` (String) The object type, which is always 'chat.completion'
- `usage` (Map of Number) Usage statistics for the chat completion request

<a id="nestedblock--messages"></a>
### Nested Schema for `messages`

Required:

- `content` (String) The content of the message
- `role` (String) The role of the message author. One of 'system', 'user', 'assistant', or 'function'

Optional:

- `function_call` (Block List, Max: 1) The name and arguments of a function that should be called, as generated by the model (see [below for nested schema](#nestedblock--messages--function_call))
- `name` (String) The name of the author of this message. Required if role is 'function'

<a id="nestedblock--messages--function_call"></a>
### Nested Schema for `messages.function_call`

Required:

- `arguments` (String) The arguments to call the function with, as a JSON string
- `name` (String) The name of the function to call



<a id="nestedblock--functions"></a>
### Nested Schema for `functions`

Required:

- `name` (String) The name of the function
- `parameters` (String) The parameters the function accepts, described as a JSON Schema object

Optional:

- `description` (String) A description of what the function does


<a id="nestedblock--choices"></a>
### Nested Schema for `choices`

Read-Only:

- `finish_reason` (String) The reason the model stopped generating text
- `index` (Number) The index of the choice in the list of choices
- `message` (List of Object) The message generated by the model (see [below for nested schema](#nestedatt--choices--message))

<a id="nestedatt--choices--message"></a>
### Nested Schema for `choices.message`

Read-Only:

- `content` (String)
- `function_call` (List of Object) (see [below for nested schema](#nestedobjatt--choices--message--function_call))
- `role` (String)

<a id="nestedobjatt--choices--message--function_call"></a>
### Nested Schema for `choices.message.function_call`

Read-Only:

- `arguments` (String)
- `name` (String)
