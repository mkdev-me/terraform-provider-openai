---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "openai_model_response Resource - terraform-provider-openai"
subcategory: ""
description: |-
  Generates text from OpenAI models using the responses API endpoint.
  Note: OpenAI response resources are immutable. Any change to input parameters
  will cause the existing resource to be deleted and a new one created. This is
  due to the nature of the OpenAI API where responses cannot be modified once
  created.
  Set preserve_on_change = true to prevent resource recreation on parameter changes.
  If preservation is enabled, the resource will show drift but will not be recreated.
---

# openai_model_response (Resource)

Generates text from OpenAI models using the responses API endpoint.
Note: OpenAI response resources are immutable. Any change to input parameters
will cause the existing resource to be deleted and a new one created. This is
due to the nature of the OpenAI API where responses cannot be modified once 
created.

Set preserve_on_change = true to prevent resource recreation on parameter changes.
If preservation is enabled, the resource will show drift but will not be recreated.

## Example Usage

```terraform
resource "openai_model_response" "logo_prompt" {
  model = "gpt-4.1-2025-04-14"
  input = <<EOF
  Create a prompt to generate super fun logo for a new Terraform OpenAI provider.
  EOF
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Optional

- `_imported_resource` (String) Internal field to prevent recreation of imported resources
- `frequency_penalty` (Number) Penalty for token frequency between -2.0 and 2.0.
- `imported` (Boolean) Internal field to track if this resource was imported
- `include` (List of String) Optional fields to include in the response.
- `input` (String) The input text to the model
- `instructions` (String) Optional instructions to guide the model.
- `max_output_tokens` (Number) The maximum number of tokens to generate.
- `model` (String) ID of the model to use (e.g., 'gpt-4o', 'gpt-4-turbo').
- `presence_penalty` (Number) Penalty for token presence between -2.0 and 2.0.
- `preserve_on_change` (Boolean) If true, preserves the existing resource when parameters change. This prevents recreation but shows drift.
- `stop_sequences` (List of String) Optional list of sequences where the API will stop generating further tokens.
- `temperature` (Number) Sampling temperature between 0 and 2. Higher values mean more randomness.
- `top_k` (Number) Top-k sampling parameter. Only consider top k tokens.
- `top_p` (Number) Nucleus sampling parameter. Top probability mass to consider.
- `user` (String) A unique identifier representing the end-user, to help track and detect abuse.

### Read-Only

- `created` (Number) Unix timestamp when the response was created.
- `finish_reason` (String) Reason why the response finished (e.g., stop, length, content).
- `id` (String) Unique identifier for this response.
- `object` (String) Object type (usually 'model_response').
- `output` (Map of String) The generated output containing text and token count.
- `usage` (Map of String) Token usage statistics for the request.
