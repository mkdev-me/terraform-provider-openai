---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "openai_vector_store_file Resource - terraform-provider-openai"
subcategory: ""
description: |-
  
---

# openai_vector_store_file (Resource)



## Example Usage

```terraform
# Example: Adding files to vector stores for use with Assistants
# Vector store files enable semantic search over document contents

# First, create a vector store
resource "openai_vector_store" "knowledge_base" {
  name = "Company Knowledge Base"
  metadata = {
    department = "engineering"
    version    = "1.0"
  }
}

# Upload files that will be added to the vector store
resource "openai_file" "technical_docs" {
  file    = "technical_documentation.pdf"
  purpose = "assistants"
}

resource "openai_file" "api_reference" {
  file    = "api_reference.md"
  purpose = "assistants"
}

resource "openai_file" "faq_document" {
  file    = "frequently_asked_questions.txt"
  purpose = "assistants"
}

# Add a file to the vector store
resource "openai_vector_store_file" "add_tech_docs" {
  # The vector store to add the file to
  vector_store_id = openai_vector_store.knowledge_base.id

  # The file to add
  file_id = openai_file.technical_docs.id

  # Optional: Chunking strategy
  chunking_strategy {
    type = "fixed"
    size = 800
  }
}

# Add API reference with auto chunking
resource "openai_vector_store_file" "add_api_ref" {
  vector_store_id = openai_vector_store.knowledge_base.id
  file_id         = openai_file.api_reference.id

  # Use automatic chunking (default)
  chunking_strategy {
    type = "auto"
  }
}

# Add FAQ document with custom chunking
resource "openai_vector_store_file" "add_faq" {
  vector_store_id = openai_vector_store.knowledge_base.id
  file_id         = openai_file.faq_document.id

  chunking_strategy {
    type = "fixed"
    size = 200 # Smaller chunks for Q&A format
  }
}

# Example: Multiple vector stores for different purposes
resource "openai_vector_store" "customer_support" {
  name = "Customer Support Database"
}

resource "openai_file" "support_tickets" {
  file    = "resolved_tickets_2024.jsonl"
  purpose = "assistants"
}

resource "openai_vector_store_file" "support_knowledge" {
  vector_store_id = openai_vector_store.customer_support.id
  file_id         = openai_file.support_tickets.id

  # Larger chunks for conversation context
  chunking_strategy {
    type = "fixed"
    size = 1200
  }
}

# Example: Code repository vector store
resource "openai_vector_store" "code_search" {
  name = "Codebase Search"
  metadata = {
    language = "python"
    project  = "backend-api"
  }
}

resource "openai_file" "source_code" {
  file    = "backend_source.zip"
  purpose = "assistants"
}

resource "openai_vector_store_file" "code_index" {
  vector_store_id = openai_vector_store.code_search.id
  file_id         = openai_file.source_code.id

  # Specific chunking for code
  chunking_strategy {
    type = "fixed"
    size = 500
  }
}

# Output file status
output "tech_docs_status" {
  value = openai_vector_store_file.add_tech_docs.status
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `file_id` (String) The ID of the file to add to the vector store.
- `vector_store_id` (String) The ID of the vector store.

### Optional

- `attributes` (Map of String) Dynamic description or tags for the file in the vector store.
- `chunking_strategy` (Block List, Max: 1) The chunking strategy used to chunk the file. (see [below for nested schema](#nestedblock--chunking_strategy))

### Read-Only

- `created_at` (Number) The timestamp for when the file was added to the vector store.
- `id` (String) The ID of the vector store file.
- `object` (String) The object type (always 'vector_store.file').
- `status` (String) The current status of the file in the vector store.

<a id="nestedblock--chunking_strategy"></a>
### Nested Schema for `chunking_strategy`

Required:

- `type` (String) The type of chunking strategy (auto, fixed, or semantic).

Optional:

- `max_tokens` (Number) The maximum tokens per chunk for semantic chunking strategy.
- `size` (Number) The size in characters for fixed chunking strategy.
