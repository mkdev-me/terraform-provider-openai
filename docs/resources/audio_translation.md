---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "openai_audio_translation Resource - terraform-provider-openai"
subcategory: ""
description: |-
  Creates an audio translation. Note: This resource does not support updates - any configuration change will create a new resource.
---

# openai_audio_translation (Resource)

Creates an audio translation. Note: This resource does not support updates - any configuration change will create a new resource.

## Example Usage

```terraform
# Example: Translating audio from various languages to English
# The Audio Translation API takes audio in any supported language and translates it to English

# Translate audio directly from file path
resource "openai_audio_translation" "translate_spanish" {
  # The audio file to translate (local file path)
  file = "./speech.mp3"

  # Model to use for translation - currently only "whisper-1" is available
  model = "whisper-1"

  # Optional: Provide a prompt to guide the translation style
  prompt = "Translate this Spanish podcast about technology into English."

  # Optional: Response format (json, text, srt, verbose_json, or vtt)
  # Default is "json" which includes the translated text
  response_format = "text"

  # Optional: Temperature for sampling (0 to 1)
  # Lower values make output more focused and deterministic
  temperature = 0.2
}

# Example with subtitle generation
resource "openai_audio_translation" "translate_with_subtitles" {
  file  = "./speech.mp3"
  model = "whisper-1"

  # Generate subtitles in SRT format
  response_format = "srt"

  # Guide the translation with context
  prompt = "This is a business presentation about quarterly results."
}

# Example with verbose JSON output
resource "openai_audio_translation" "translate_verbose" {
  file  = "./speech.mp3"
  model = "whisper-1"

  # Get detailed output with segments
  response_format = "verbose_json"
  temperature     = 0
}

# Output the translation result
output "translated_text" {
  value = openai_audio_translation.translate_spanish.text
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `file` (String) Path to the audio file to translate (format: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm)
- `model` (String) ID of the model to use. Currently only 'whisper-1' is supported for audio translation.

### Optional

- `prompt` (String) An optional text to guide the model's style or continue a previous audio segment. The prompt should be in English.
- `response_format` (String) The format of the translation output
- `temperature` (Number) The sampling temperature, between 0 and 1

### Read-Only

- `duration` (Number) The duration of the audio in seconds
- `id` (String) The ID of this resource.
- `segments` (List of Object) (see [below for nested schema](#nestedatt--segments))
- `text` (String) The translated text

<a id="nestedatt--segments"></a>
### Nested Schema for `segments`

Read-Only:

- `avg_logprob` (Number)
- `compression_ratio` (Number)
- `end` (Number)
- `id` (Number)
- `no_speech_prob` (Number)
- `seek` (Number)
- `start` (Number)
- `temperature` (Number)
- `text` (String)
- `tokens` (List of Number)
